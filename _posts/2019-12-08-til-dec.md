---
layout: single
title:  "TIL(12월)"
date:   2019-12-08 12:00:59 +0900
classes: wide
categories: etc
tags: web
---

**틀린 내용이나 본문의 내용과 다른 의견이 있으시면 댓글로 남겨주세요!**

## 12/17

### StringBuilder, StringBuffer

StringBuffer는 Thread-safe 하다.

StringBuilder, StringBuffer는 String과 비슷하지만 수정가능하다.

String은 `String a = "abcd"; String b = a + "efg"` 와 같이 선언하면 객체 주소가 바뀐다.

## 12/16

### Wrapper Class vs. Primitive Type

객체를 쓰는 것은 원시 타입을 사용하는 것보다 메모리나 박싱 측면에서 오버헤드가 있다.

오브젝트는 null로 초기화가 가능하고, 메서드나 생성자에 null을 넘길 수도 있다.(원시타입은 안된다.)

Wrapper class는 null 을 반환할 필요가 있을 때나, 객체로 필요할 경우에 사용한다.(generic)

JPA에서 객체를 생성할 때 일단 DB에 들어가기 전에는 id값이 없다. 그래서 null이 필요할 수 있다.

## 12/11

### WebSocket

원격 호스트와 양방향 통신 프로토콜이다. WebSocket은 polling 방식 때문에 생기는 불필요한 네트워크 트래픽과 지연시간을 줄여준다. 단일 커넥션으로 upstream, downstream을 지원한다.

WebSocket 프로토콜은 이미 있던 웹 인프라에서 잘 동작하는 것을 기반으로 디자인 되었다. 그래서 프로토콜의 스펙은 HTTP connection의 life로부터 시작된다. HTTP로부터 WebSocket으로의 변환은 WebSocket handshake로 할 수 있다.

### HTTP 에서 WebSocket으로 프로토콜 전환

HTTP의 Header에 Upgrade 속성을 추가하여 서버에 보냄, 이 WebSocket 프로토콜을 이해하는 서버라면, Upgrade 속성으로 프로토콜 전환을 하고 ws프로토콜을 사용하게 된다.

```request
GET ws://echo.websocket.org/?encoding=text HTTP/1.1
Origin: http://websocket.org
Cookie: __utma=99as
Connection: Upgrade
Host: echo.websocket.org
Sec-WebSocket-Key: uRovscZjNol/umbTt5uKmw==
Upgrade: websocket
Sec-WebSocket-Version: 13
```

```response
HTTP/1.1 101 WebSocket Protocol Handshake
Date: Fri, 10 Feb 2012 17:38:18 GMT
Connection: Upgrade
Server: Kaazing Gateway
Upgrade: WebSocket
Access-Control-Allow-Origin: http://websocket.org
Access-Control-Allow-Credentials: true
Sec-WebSocket-Accept: rLHCkw/SKsO9GAH/ZSFhBATDKrU=
Access-Control-Allow-Headers: content-type
```

### 참고자료(WebSocket)

- [http://www.websocket.org/aboutwebsocket.html](http://www.websocket.org/aboutwebsocket.html)
- [https://spring.io/guides/gs/messaging-stomp-websocket/](https://spring.io/guides/gs/messaging-stomp-websocket/)

## 12/08

### What is a Reverse Proxy vs. Load Balancer

각각의 뜻은 간단하다.

리버스 프록시는 클라이언트로부터 요청을 받고 서버로 그 요청을 포워딩 해주고, 서버로부터 받은 응답을 클라이언트로 되돌려 준다.

로드 밸런서는 들어오는 클라이언트의 요청을 여러 서버들로 분배 해준다. 서버로부터 온 응답은 적합한 클라이언트에 되돌려 준다. 말로는 엄청 간단해보인다. 리버스 프록시와 로드 밸런서 모두 클라이언트와 서버 사이에 위치해 있다(요청을 받아서 응답을 전달해준다는 측면에서).

### Load Balancing

로드 밸런서는 일반적으로 한 서버로 오는 요청이 효율적으로 처리하기에는 너무 커서 사이트가 여러 서버를 필요로 할 때 사용한다. 여러 서버를 배포하는 것은 SPOF를 없애주고 웹사이트를 좀 더 신뢰성 있게 해준다. 일반적으로 서버는 모두 동일한 컨텐츠를 호스트하고, 로드 밸런서의 일은 각 서버의 용량을 최대한 활용하고, 서버에 과부하를 방지하며, 클라이언트에 가능한 가장 빠른 응답을 하는 방식으로 워크로드를 분배하는 것이다.

로드 밸런서는 클라이언트가 보는 에러 응답의 수를 줄임으로써 사용자 경험을 향상 시킬 수 있다. 서버가 다운되는 경우를 감지하고, 요청을 그룹 내의 다른 서버로 분산시킴으로써 이것을 실현시킨다. 가장 간단한 구현에서, 로드 밸런서는 규칙적인 요청으로부터 에러 응답을 감지해 서버의 상태를 감지한다. 애플리케이션의 health check는 좀 더 유연하고 정교한 방법(로드 밸런서가 헬스 체크 요청을 보내고, 그 헬스 체크를 고려한 타입의 요청)이다.

어떤 로드 밸런서의 또 다른 유용한 기능은 특정한 클라이언트로부터 오는 모든 요청은 같은 서버로 보내는 세션 유지이다. HTTP는 이론 상 무상태 프로토콜이지만, 많은 애플리케이션은 그들의 핵심 기능을 제공하기 위해서 상태 정보를 저장해야 한다. 그런 애플리케이션들은 이런 로드 밸런싱 환경에서 로드 밸런서가 처음 요청에 대한 응답을 한 서버로만 하나의 유저 세션을 고정하지 않고, 한 유저 세션의 요청을 여러 다른 서버로 나누어 버리는 경우에 기능 수행이 제대로 안될 수 있다.

### Reverse Proxy

여러 서버를 필요로 한다면 로드 밸런서를 사용하는 것이 옳지만, 단일 웹서버나 WAS를 사용하더라도 리버스 프록시를 사용하는 것이 좋다. 간단하게 생각해서 리버스 프록시는 웹사이트의 `public face`라고 생각하면 된다. 그 주소는 웹사이트에 광고된 것이고, 그것은 웹사이트에서 호스팅되는 콘텐츠에 대한 요청을 받아들이기 위해 네트워크의 edge에 위치한다.(?) 장점은 두 가지가 있다.

1. 보안 향상 - 내부 네트워크 외부에서 백엔드 서버에 대한 정보가 없기 때문에, 악의를 가진 클라이언트가 취약점을 이용하기 위해 직접 서버에 접근할 수 없게 한다. 많은 리버스 프록시 서버는 DDoS 공격으로부터 백엔드 서버를 보호하는 기능을 포함하고 있다. (특정 아이피로 들어오는 트래픽을 차단하거나, 각 클라이언트로부터 오는 connection 수를 제한 한다거나..)
2. 확장성 및 유연성 향상 - 클라이언트는 리버스 프록시의 아이피만을 알기 때문에, 백엔드 서버 인프라 구조의 설정을 자유롭게 바꿀 수 있다. 이는 트래픽양에 따라 서버의 수를 늘리거나 줄이는 로드 밸런싱 된 환경에서 특히 유용하다.
3. 또 다른 이유는 웹 가속화를 위해 리버스 프록시를 사용한다. - 응답을 만들고, 클라이언트로 응답을 되돌려주는 시간을 줄여준다. 그 방법은 아래와 같다.
   1. 압축 – 클라이언트로 반환 하기전에 서버의 응답을 압축(예를 들면, gzip)하면 필요한 대역폭을 줄일 수 있어서 네트워크를 통한 전송속도를 높여준다.
   2. SSL termination – 클라이언트와 서버간의 트래픽을 암호화 하면, 인터넷 같은 퍼블릭 네트워크를 통해서 통신할 때 정보를 보호할 수 있다. 그러나 암호화, 복호화는 계산적으로 비쌀 수 있다. 요청을 복호화하고, 서버의 응답을 암호화함으로써 리버스 프록시는 백엔드 서버의 리소스를 본인의 역할(컨텐츠 제공)에 충실할 수 있도록 해준다.
   3. 캐싱 - 백엔드 서버의 응답을 클라이언트로 반환하기 전에 리버스 프록시는 그 응답을 로컬에 저장한다. 클라이언트가 똑같은 요청을 만들어서 보낸다면, 리버스 프록시는 요청을 백엔드 서버로 포워딩 하지 않고, 리버스 프록시의 캐시로부터 응답을 만들어서 보낼 수 있다. 이를 통해 응답 속도를 올리고, 백엔드 서버의 부하를 줄여준다.

### 참고자료(Reverse Proxy vs. Load Balancer)

- [nginx docs](https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/)
